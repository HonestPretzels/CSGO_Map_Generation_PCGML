# SPLIT
netInput = input_data([None, inputShape[1]])

dataFlat = tf.slice(netInput, [0,0], [-1, SECONDS*PLAYERS*STATE_LENGTH])
mapFlat = tf.slice(netInput, [0, SECONDS*PLAYERS*STATE_LENGTH], [-1, -1])

dataInput = tf.reshape(dataFlat, [-1, SECONDS, PLAYERS*STATE_LENGTH])
mapInput = tf.reshape(mapFlat, [-1, MAP_DEPTH, MAP_SCALE, MAP_SCALE])

# MAP HEAD
conv1 = conv_2d(mapInput,16, 3, activation="relu")
dropped = dropout(conv1, 0.5)
pooled1 = max_pool_2d(dropped, 2, strides=2)
conv2 = conv_2d(pooled1, 32, 3, activation="relu")
pooled2 = max_pool_2d(conv2, 2, strides=2)
flatMap = tflearn.flatten(pooled2)

# DATA HEAD
lstm1 = lstm(dataInput, 128, dropout=0.8, return_seq=True)
lstm2 = lstm(lstm1, 128)
flatData = tflearn.flatten(lstm2)

# RECOMBINE 
combined = tf.concat([flatData, flatMap], 1)
fc1 = fully_connected(combined, 128)
fc2 = fully_connected(fc1, 64)
fc3 = fully_connected(fc2, 2, activation="softmax")
out = regression(fc3, optimizer="adam", learning_rate=0.001, loss="categorical_crossentropy")

model = DNN(out)
return model